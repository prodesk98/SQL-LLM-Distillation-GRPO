{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "import re"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "MAX_SEQ_LEN = 1024\n",
    "MAX_PROMPT_LENGTH = 256\n",
    "MODEL_NAME = \"unsloth/Llama-3.2-1B-Instruct\""
   ],
   "id": "92ed885c1d35bc9b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = MODEL_NAME,\n",
    "    max_seq_length = MAX_SEQ_LEN,\n",
    "    load_in_4bit = True,\n",
    "    load_in_8bit = False,\n",
    ")"
   ],
   "id": "a033b607950891a8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = 16,\n",
    "    target_modules = [\n",
    "        \"q_proj\",\n",
    "        \"k_proj\",\n",
    "        \"v_proj\",\n",
    "        \"o_proj\",\n",
    "        \"gate_proj\",\n",
    "        \"up_proj\",\n",
    "        \"down_proj\",\n",
    "    ],\n",
    "    lora_alpha = 16,\n",
    "    lora_dropout = 0,\n",
    "    bias = \"none\",\n",
    "    use_gradient_checkpointing = \"unsloth\",\n",
    "    random_state = 3407,\n",
    "    max_seq_length = MAX_SEQ_LEN,\n",
    "    use_rslora = False,\n",
    "    loftq_config = None,\n",
    ")"
   ],
   "id": "670c9665c0533352",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"proton98/sql-gpt-4.1-nano-distill-reasoning-data\", split=\"train\")"
   ],
   "id": "d0ae9d6ec7935e9b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "dataset.shuffle(seed=42).select(range(10))[0][\"generation\"]",
   "id": "fafdb913fab87522",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def extract_answer(text: str) -> str | None:\n",
    "    sql_match = re.search(r\"<sql>(.*?)</sql>\", text, re.DOTALL)\n",
    "    if sql_match:\n",
    "        return sql_match.group(1).strip()"
   ],
   "id": "3eb1286cbc18c69b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def extract_schema(sql: str) -> str:\n",
    "    table_pattern = re.compile(\n",
    "        r\"CREATE TABLE (\\w+)\\s*\\((.*?)\\);\", re.DOTALL | re.IGNORECASE\n",
    "    )\n",
    "\n",
    "    column_pattern = re.compile(r\"\\s*(\\w+)\\s+([\\w()]+)\")\n",
    "\n",
    "    schema_lines: list[str] = [\"Tables:\"]\n",
    "\n",
    "    for match in table_pattern.finditer(sql):\n",
    "        table_name, columns_block = match.groups()\n",
    "        schema_lines.append(f\"\\n- {table_name}\")\n",
    "        for col_line in columns_block.strip().split(\",\"):\n",
    "            col_line = col_line.strip()\n",
    "            col_match = column_pattern.match(col_line)\n",
    "            if col_match:\n",
    "                col_name, col_type = col_match.groups()\n",
    "                schema_lines.append(f\"  - {col_name} ({col_type.upper()})\")\n",
    "\n",
    "    return \"\\n\".join(schema_lines)"
   ],
   "id": "edfaf1ca1e9f57cd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "extract_answer(dataset.shuffle(seed=42).select(range(10))[0][\"generation\"][0])",
   "id": "b739eada48b2e75b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "REASONING_START = \"<think>\"\n",
    "REASONING_END = \"</think>\"\n",
    "SOLUTION_START = \"<sql>\"\n",
    "SOLUTION_END = \"</sql>\"\n",
    "\n",
    "SYSTEM_PROMPT = \\\n",
    "f\"\"\"You are an expert in writing optimized SQL queries.\n",
    "Think about the problem and provide your working out.\n",
    "Place it between {REASONING_START} and {REASONING_END}.\n",
    "Then, provide your solution between {SOLUTION_START} and {SOLUTION_END}.\n",
    "\n",
    "Context:\n",
    "{{context}}\"\"\"\n",
    "SYSTEM_PROMPT"
   ],
   "id": "5abacd29fd67e88b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "dataset = dataset.map(\n",
    "    lambda x: {\n",
    "        \"prompt\": [\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT.format(context=extract_schema(x[\"sql_context\"]))},\n",
    "            {\"role\": \"user\", \"content\": x[\"sql_prompt\"]},\n",
    "        ],\n",
    "        \"answer\": extract_answer(next(iter(x[\"generation\"]))),\n",
    "    },\n",
    ")"
   ],
   "id": "47391313373bc8d7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "match_format = re.compile(\n",
    "    rf\"\\s*{REASONING_START}(?P<thinking>.+?){REASONING_END}\\s*\"\n",
    "    rf\"{SOLUTION_START}(?P<sql>.+?){SOLUTION_END}\\s*\",\n",
    "    flags=re.DOTALL\n",
    ")"
   ],
   "id": "25f1a8476a105d59",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "match_format.search(\n",
    "f\"\"\"\n",
    "{REASONING_START}\n",
    "Hello\n",
    "{REASONING_END}\n",
    "{SOLUTION_START}\n",
    "SELECT * FROM table WHERE condition;\n",
    "{SOLUTION_END}\n",
    "\"\"\"\n",
    ")"
   ],
   "id": "9cb9acb5cd2658bf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def match_format_exactly(completions: list[dict], **kwargs):\n",
    "    scores: list[float] = []\n",
    "    for completion in completions:\n",
    "        score = 0\n",
    "        response = next(iter(completion))[\"content\"]\n",
    "        if match_format.search(response) is not None: score += 3.0\n",
    "        scores.append(score)\n",
    "    return scores"
   ],
   "id": "5ec4156c2283ec05",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def match_format_approximately(completions, **kwargs):\n",
    "    scores: list[float] = []\n",
    "    for completion in completions:\n",
    "        score = 0\n",
    "        response: str = next(iter(completion))[\"content\"]\n",
    "        score += 0.5 if response.count(REASONING_START) == 1 else -0.5\n",
    "        score += 0.5 if response.count(REASONING_END) == 1 else -0.5\n",
    "        score += 0.5 if response.count(SOLUTION_START) == 1 else -0.5\n",
    "        score += 0.5 if response.count(SOLUTION_END) == 1 else -0.5\n",
    "        scores.append(score)\n",
    "    return scores"
   ],
   "id": "e9649ede4206352f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def check_answer(prompts, completions, answer, **kwargs):\n",
    "    responses = [next(iter(completion))[\"content\"] for completion in completions]\n",
    "\n",
    "    extracted_responses = [\n",
    "        guess.group(1)\n",
    "        if (guess := match_format.search(r)) is not None else None \\\n",
    "        for r in responses\n",
    "    ]\n",
    "\n",
    "    scores: list[float] = []\n",
    "    for guess, true_answer in zip(extracted_responses, answer):\n",
    "        score = 0\n",
    "        if guess is None:\n",
    "            scores.append(.0)\n",
    "            continue\n",
    "        if guess == true_answer:\n",
    "            score += 3.0\n",
    "        elif guess.strip() == true_answer.strip():\n",
    "            score += 1.5\n",
    "        scores.append(score)\n",
    "    return scores"
   ],
   "id": "1163d61b2317050d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "from trl import GRPOConfig, GRPOTrainer",
   "id": "f75aeee37f024903",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "training_args = GRPOConfig(\n",
    "    learning_rate = 5e-6,\n",
    "    adam_beta1 = 0.9,\n",
    "    adam_beta2 = 0.99,\n",
    "    weight_decay = 0.1,\n",
    "    warmup_ratio = 0.1,\n",
    "    lr_scheduler_type = \"cosine\",\n",
    "    optim = \"adamw_torch_fused\",\n",
    "    logging_steps = 1,\n",
    "    per_device_train_batch_size = 1,\n",
    "    gradient_accumulation_steps = 1, # Increase to 4 for smoother training\n",
    "    num_generations = 4, # Decrease if out of memory\n",
    "    max_prompt_length = MAX_PROMPT_LENGTH,\n",
    "    max_completion_length = MAX_SEQ_LEN - MAX_PROMPT_LENGTH,\n",
    "    # num_train_epochs = 1, # Set to 1 for a full training run\n",
    "    max_steps = 50,\n",
    "    save_steps = 50,\n",
    "    max_grad_norm = 0.1,\n",
    "    report_to = \"none\", # Can use Weights & Biases\n",
    "    output_dir = \"outputs\",\n",
    ")"
   ],
   "id": "bccad4ac7ea777e9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "trainer = GRPOTrainer(\n",
    "    model = model,\n",
    "    processing_class = tokenizer,\n",
    "    reward_funcs = [\n",
    "        match_format_exactly,\n",
    "        match_format_approximately,\n",
    "        check_answer,\n",
    "    ],\n",
    "    args = training_args,\n",
    "    train_dataset = dataset,\n",
    ")"
   ],
   "id": "65204525eedf904e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "trainer.train()",
   "id": "a6e68687dd5bf898",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "a7850491a4ce0430",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
