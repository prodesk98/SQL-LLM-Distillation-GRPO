{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T21:38:01.082264Z",
     "start_time": "2025-05-19T21:37:31.158402Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datasets import load_dataset, DatasetDict, Dataset\n",
    "from unsloth import FastLanguageModel, is_bfloat16_supported\n",
    "from trl import GRPOConfig, GRPOTrainer\n",
    "import duckdb\n",
    "import re"
   ],
   "id": "5665a5b451363cb4",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n",
      "INFO 05-19 21:37:57 [importing.py:53] Triton module has been replaced with a placeholder.\n",
      "INFO 05-19 21:37:57 [__init__.py:239] Automatically detected platform cuda.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-19 21:37:58,976\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Load the dataset",
   "id": "7887bf9886c781e6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T21:38:29.196487Z",
     "start_time": "2025-05-19T21:38:04.520911Z"
    }
   },
   "cell_type": "code",
   "source": [
    "DATASET_REPO_ID = \"proton98/sql-distill-llama-3-1-70b-instruct-reasoning\"\n",
    "dataset_train = load_dataset(DATASET_REPO_ID, split=\"train\")"
   ],
   "id": "357ae22d05c03713",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Prompt template",
   "id": "4a3fb6be01916a01"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T21:38:32.379261Z",
     "start_time": "2025-05-19T21:38:32.374959Z"
    }
   },
   "cell_type": "code",
   "source": [
    "REASONING_START = \"<think>\"\n",
    "REASONING_END = \"</think>\"\n",
    "SOLUTION_START = \"<sql>\"\n",
    "SOLUTION_END = \"</sql>\"\n",
    "\n",
    "REASONING_SYSTEM_PROMPT_TEMPLATE = \\\n",
    "f\"\"\"You are an expert in writing optimized SQL queries.\n",
    "Think about the problem and provide your working out.\n",
    "Place it between {REASONING_START} and {REASONING_END}.\n",
    "Then, provide your solution between {SOLUTION_START} and {SOLUTION_END}.\n",
    "\n",
    "Context:\n",
    "{{context}}\"\"\".rstrip()"
   ],
   "id": "d32eedcd72de965d",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Process the dataset",
   "id": "c3186982cc4bb69a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T21:38:34.319123Z",
     "start_time": "2025-05-19T21:38:34.299308Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sql_match_format = re.compile(rf\"{SOLUTION_START}(.*?){SOLUTION_END}\", re.DOTALL)\n",
    "reasoning_match_format = re.compile(rf\"{REASONING_START}(.*?){REASONING_END}\", re.DOTALL)\n",
    "\n",
    "def extract_sql(text: str) -> str | None:\n",
    "    \"\"\"\n",
    "    Extracts the SQL using regex from the generated text.\n",
    "    :param text:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    sql_match = sql_match_format.search(text)\n",
    "    if sql_match:\n",
    "        return sql_match.group(1).strip()\n",
    "\n",
    "\n",
    "def extract_think(text: str) -> str | None:\n",
    "    \"\"\"\n",
    "    Extracts the think using regex from the generated text.\n",
    "    :param text:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    think_match = reasoning_match_format.search(text)\n",
    "    if think_match:\n",
    "        return think_match.group(1).strip()\n",
    "\n",
    "\n",
    "def _reasoning_format(content: str) -> str:\n",
    "    \"\"\"\n",
    "    Formatting prompt for exact match.\n",
    "    :param content:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    __think = extract_think(content)\n",
    "    __sql = extract_sql(content)\n",
    "    return f\"\"\"{REASONING_START}\\n{__think}\\n{REASONING_END}\\n{SOLUTION_START}\\n{__sql}\\n{SOLUTION_END}\"\"\"\n",
    "\n",
    "\n",
    "def conversations_formatting(dataset: DatasetDict) -> Dataset | DatasetDict:\n",
    "    \"\"\"\n",
    "    Format the conversations for the model.\n",
    "    :param dataset:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    dataset = dataset.map(lambda x: {\n",
    "        \"prompt\": [\n",
    "            {\"role\": \"system\", \"content\": REASONING_SYSTEM_PROMPT_TEMPLATE.format(context=x[\"sql_context\"])},\n",
    "            {\"role\": \"user\", \"content\": x[\"sql_prompt\"]},\n",
    "            {\"role\": \"assistant\", \"content\": _reasoning_format(x[\"generation\"])},\n",
    "        ],\n",
    "        \"questions\": x[\"sql_prompt\"],\n",
    "        \"contexts\": x[\"sql_context\"],\n",
    "        \"answers\": extract_sql(x[\"generation\"]),\n",
    "    })\n",
    "    return dataset\n",
    "\n",
    "\n",
    "dataset_train = conversations_formatting(dataset_train)"
   ],
   "id": "7ed4137dc0cb0a5a",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Load the model and tokenizer",
   "id": "aa0a5180d6306fe6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T21:39:22.446456Z",
     "start_time": "2025-05-19T21:38:36.177541Z"
    }
   },
   "cell_type": "code",
   "source": [
    "MODEL_PATH_NAME = \"unsloth/gemma-3-1b-it\"\n",
    "MAX_SEQ_LEN = 4096\n",
    "MAX_LORA_RANK = 16\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = MODEL_PATH_NAME,\n",
    "    max_seq_length = MAX_SEQ_LEN,\n",
    "    load_in_4bit = True,\n",
    "    fast_inference = True,\n",
    "    max_lora_rank = MAX_LORA_RANK,\n",
    "    gpu_memory_utilization = 0.7,\n",
    ")\n",
    "\n",
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = 16,\n",
    "    lora_alpha = 16,\n",
    "    lora_dropout = 0,\n",
    "    bias = \"none\",\n",
    "    random_state = 3407,\n",
    "    use_rslora = False,\n",
    ")"
   ],
   "id": "320f38bf6b87e9a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.5.6: Fast Gemma3 patching. Transformers: 4.51.3. vLLM: 0.8.5.post1.\n",
      "   \\\\   /|    NVIDIA GeForce RTX 3060. Num GPUs = 1. Max memory: 12.0 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 8.6. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29.post2. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
      "Unsloth: Making `model.base_model.model.model` require gradients\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Function rewards",
   "id": "36b95079a0825fca"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "COLORED_GREEN = \"\\033[92m\"\n",
    "COLORED_BLUE = \"\\033[94m\"\n",
    "COLORED_RESET = \"\\033[0m\"\n",
    "BOLD = \"\\033[1m\"\n",
    "\n",
    "response_match_format = re.compile(\n",
    "    rf\"^{REASONING_START}\\n.*?\\n{REASONING_END}\\n{SOLUTION_START}\\n.*?\\n{SOLUTION_END}$\",\n",
    "    re.DOTALL | re.MULTILINE\n",
    ")\n",
    "\n",
    "\n",
    "def match_format_exactly(completions: list[list[dict[str, str]]], **kwargs) -> list[float]: # noqa\n",
    "    \"\"\"\n",
    "    Check if the completions match the expected format exactly.\n",
    "    :param completions:\n",
    "    :param kwargs:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    scores: list[float] = []\n",
    "    for completion in completions:\n",
    "        score = 0\n",
    "        response = completion[0][\"content\"]\n",
    "        if response_match_format.search(response) is not None: score += 3.0\n",
    "        scores.append(score)\n",
    "    return scores\n",
    "\n",
    "\n",
    "def match_format_approximately(completions: list[list[dict[str, str]]], **kwargs) -> list[float]: # noqa\n",
    "    \"\"\"\n",
    "    Check if the completions match the expected format approximately.\n",
    "    :param completions:\n",
    "    :param kwargs:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    scores: list[float] = []\n",
    "    for completion in completions:\n",
    "        score = 0\n",
    "        response = completion[0][\"content\"]\n",
    "        score += 0.125 if response.count(f\"{REASONING_START}\\n\")    == 1 else -1.0\n",
    "        score += 0.125 if response.count(f\"\\n{REASONING_END}\\n\")    == 1 else -1.0\n",
    "        score += 0.125 if response.count(f\"\\n{SOLUTION_START}\\n\")   == 1 else -1.0\n",
    "        score += 0.125 if response.count(f\"\\n{SOLUTION_END}\")       == 1 else -1.0\n",
    "        scores.append(score)\n",
    "    return scores\n",
    "\n",
    "\n",
    "def validate_sql_query(sql_query: str, context: str) -> tuple[bool, str]:\n",
    "    \"\"\"\n",
    "    Validate the SQL query against the provided context.\n",
    "\n",
    "    Args:\n",
    "        sql_query (str): The SQL query to validate.\n",
    "        context (str): The context in which the SQL query is executed\n",
    "            (e.g., table schema, data).\n",
    "    Returns:\n",
    "        tuple[bool, str]: Whether the SQL query is valid.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        con = duckdb.connect(database=':memory:')\n",
    "\n",
    "        context_statements = [stmt.strip() for stmt in context.strip().split(';') if stmt.strip()]\n",
    "        for statement in context_statements:\n",
    "            con.execute(statement)\n",
    "\n",
    "        con.execute(sql_query)\n",
    "        _ = con.fetchall()\n",
    "\n",
    "        return True, \"SQL query is valid and executed successfully.\"\n",
    "    except Exception as e:\n",
    "        return False, str(e)\n",
    "\n",
    "\n",
    "def check_sql_reward(\n",
    "    prompts: list[list[dict[str, str]]],\n",
    "    completions: list[list[dict[str, str]]],\n",
    "    questions: list[str],\n",
    "    answers: list[str],\n",
    "    contexts: list[str],\n",
    "    **kwargs # noqa\n",
    ") -> list[float]:\n",
    "    \"\"\"\n",
    "    Check the SQL reward for the given prompts and completions.\n",
    "    :param prompts:\n",
    "    :param completions:\n",
    "    :param questions:\n",
    "    :param answers:\n",
    "    :param contexts:\n",
    "    :param kwargs:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    responses = [completion[0][\"content\"] for completion in completions]\n",
    "    pred_responses: list[str | None] = [extract_sql(r) for r in responses]\n",
    "\n",
    "    print(\n",
    "        '-'*20,\n",
    "        f\"{BOLD}Question:{COLORED_RESET} {questions[0]}{COLORED_RESET}\",\n",
    "        f\"\\n{BOLD}Response:{COLORED_RESET} \\n{COLORED_GREEN}{responses[0]}{COLORED_RESET}\",\n",
    "        f\"\\n{BOLD}Real Answer:{COLORED_RESET} \\n{COLORED_GREEN}{answers[0]}{COLORED_RESET}\",\n",
    "        f\"\\n{BOLD}Extracted:{COLORED_RESET} \\n\"\n",
    "        f\"{COLORED_BLUE}{pred_responses[0] if pred_responses[0] is not None else '-Invalid Format-'}{COLORED_RESET}\",\n",
    "    )\n",
    "\n",
    "    scores: list[float] = []\n",
    "    for pred, context, answer in zip(pred_responses, contexts, answers):\n",
    "        score = 0\n",
    "        if pred is None:\n",
    "            scores.append(0)\n",
    "            continue\n",
    "\n",
    "        # Check if the SQL query is valid\n",
    "        is_valid, _ = validate_sql_query(pred, context)\n",
    "\n",
    "        # Check if the SQL query is similar to the true SQL\n",
    "        # Correct answer gets 3 points\n",
    "        if is_valid:\n",
    "            # Exact match\n",
    "            if pred == answer: score += 3.0\n",
    "            # Match if spaces are seen\n",
    "            elif pred.strip() == answer.strip(): score += 1.5\n",
    "        else: score -= 1.5 # Penalty for incorrect SQL\n",
    "        scores.append(score)\n",
    "    return scores\n"
   ],
   "id": "ee83b92c68292daa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Training",
   "id": "8a61508e24236688"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "MAX_PROMPT_LEN = 2048\n",
    "MAX_COMPLETION_LEN = 1024\n",
    "\n",
    "training_args = GRPOConfig(\n",
    "    use_vllm = True,\n",
    "    learning_rate = 5e-6,\n",
    "    adam_beta1 = 0.9,\n",
    "    adam_beta2 = 0.99,\n",
    "    weight_decay = 0.1,\n",
    "    warmup_ratio = 0.1,\n",
    "    lr_scheduler_type = \"cosine\",\n",
    "    optim = \"paged_adamw_8bit\",\n",
    "    logging_steps = 1,\n",
    "    bf16 = is_bfloat16_supported(),\n",
    "    fp16 = not is_bfloat16_supported(),\n",
    "    per_device_train_batch_size = 8,\n",
    "    gradient_accumulation_steps = 1,\n",
    "    num_generations = 4,\n",
    "    max_prompt_length = MAX_PROMPT_LEN,\n",
    "    max_completion_length = MAX_COMPLETION_LEN,\n",
    "    max_steps = 100,\n",
    "    save_steps = 250,\n",
    "    max_grad_norm = 0.1,\n",
    "    report_to = \"none\",\n",
    "    output_dir = \"outputs\",\n",
    ")"
   ],
   "id": "7e7c4c7a0b399b57",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "trainer = GRPOTrainer(\n",
    "    model = model,\n",
    "    processing_class = tokenizer,\n",
    "    reward_funcs = [ # type: ignore\n",
    "        match_format_exactly,\n",
    "        match_format_approximately,\n",
    "        check_sql_reward,\n",
    "    ],\n",
    "    args = training_args,\n",
    "    train_dataset = dataset_train,\n",
    ")\n",
    "trainer.train()"
   ],
   "id": "1e5a2b0bb800517c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "f5f67b3a3e84f407",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
