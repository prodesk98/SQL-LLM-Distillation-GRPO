{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "import re\n",
    "from os import environ\n",
    "from dotenv import load_dotenv\n",
    "from distilabel.models.llms import OpenAILLM\n",
    "from distilabel.pipeline import Pipeline\n",
    "from distilabel.steps.tasks import TextGeneration\n",
    "\n",
    "load_dotenv()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "dataset = load_dataset(\"gretelai/synthetic_text_to_sql\", split=\"train\").select(range(10))",
   "id": "c3066ef3a7708bc7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "BASE_URL = \"https://api.openai.com/v1\"\n",
    "API_KEY = environ.get(\"OPENAI_API_KEY\")\n",
    "MODEL = \"gpt-4.1-nano\"\n",
    "GENERATION_KWARGS = {\n",
    "    \"temperature\": 0.2,\n",
    "    \"max_new_tokens\": 1024,\n",
    "}\n",
    "PROMPT_TEMPLATE = \"\"\"\\\n",
    "You are an expert in writing optimized SQL queries, with strong logical reasoning skills.\n",
    "\n",
    "Follow these guidelines:\n",
    "- Use <think></think> tags to explain your reasoning process step by step.\n",
    "- Use <sql></sql> tags to present the final SQL query.\n",
    "\n",
    "Instruction:\n",
    "{{ instruction }}\n",
    "\n",
    "Context:\n",
    "{{ context }}\n",
    "\n",
    "Explanation:\n",
    "{{ explanation }}\n",
    "\n",
    "Expected Output:\n",
    "<think>\n",
    "1. Interpret the instruction and context to determine the requirements.\n",
    "2. Identify relevant tables, columns, filters, and relationships.\n",
    "3. Formulate a clear and efficient SQL query that meets the requirements.\n",
    "4. Optimize the query for performance and accuracy.\n",
    "5. Briefly explain the logic behind the query.\n",
    "6. Ensure the output matches both instruction and context.\n",
    "</think>\n",
    "<sql>\n",
    "Final SQL query goes here\n",
    "</sql>\"\"\".rstrip()\n",
    "PROMPT_COLUMN = \"sql_prompt\"\n",
    "CONTEXT_COLUMN = \"sql_context\"\n",
    "EXPLANATION_COLUMN = \"sql_explanation\"\n",
    "INPUT_BATCH_SIZE = 16\n",
    "NUM_GENERATIONS = 1"
   ],
   "id": "e3764cf70f5c0cca",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "with Pipeline() as pipeline:\n",
    "    TextGeneration(\n",
    "        llm=OpenAILLM(\n",
    "            base_url=BASE_URL,\n",
    "            api_key=API_KEY,\n",
    "            model=MODEL,\n",
    "            generation_kwargs=GENERATION_KWARGS,\n",
    "        ),\n",
    "        template=PROMPT_TEMPLATE,\n",
    "        columns=[\n",
    "            \"instruction\",\n",
    "            \"context\",\n",
    "            \"explanation\"\n",
    "        ],\n",
    "        input_mappings={\n",
    "            \"instruction\": PROMPT_COLUMN,\n",
    "            \"context\": CONTEXT_COLUMN,\n",
    "            \"explanation\": EXPLANATION_COLUMN\n",
    "        },\n",
    "        input_batch_size=INPUT_BATCH_SIZE,\n",
    "        num_generations=NUM_GENERATIONS,\n",
    "        group_generations=True,\n",
    "    )"
   ],
   "id": "dae1e0515d5c4293",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def extract_sql(text: str) -> str | None:\n",
    "    \"\"\"\n",
    "    Extracts the SQL using regex from the generated text.\n",
    "    :param text:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    sql_match = re.search(r\"<sql>(.*?)</sql>\", text, re.DOTALL)\n",
    "    if sql_match:\n",
    "        return sql_match.group(1).strip()\n",
    "\n",
    "def extract_think(text: str) -> str | None:\n",
    "    \"\"\"\n",
    "    Extracts the think using regex from the generated text.\n",
    "    :param text:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    think_match = re.search(r\"<think>(.*?)</think>\", text, re.DOTALL)\n",
    "    if think_match:\n",
    "        return think_match.group(1).strip()"
   ],
   "id": "db9bc8e502a0e62e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "distiset = pipeline.run(dataset=dataset)",
   "id": "c846ca1ad1197fe6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "COLORED_GREEN = \"\\033[92m\"\n",
    "COLORED_BLUE = \"\\033[94m\"\n",
    "COLORED_RESET = \"\\033[0m\"\n",
    "\n",
    "for generate in distiset['default']['train']['generation']:\n",
    "    _next = next(iter(generate))\n",
    "    think = extract_think(_next)\n",
    "    sql = extract_sql(_next)\n",
    "    print(f\"Think: {COLORED_BLUE}{think}{COLORED_RESET}\")\n",
    "    print(f\"SQL: {COLORED_GREEN}{sql}{COLORED_RESET}\")\n",
    "    print(\"-\" * 20)"
   ],
   "id": "c44b9aa00c665072",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "9635290c00d0c63f",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
