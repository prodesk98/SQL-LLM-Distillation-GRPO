services:
  train_sm_86:
    build:
      context: .
      dockerfile: dockers/train_sm_86.Dockerfile
    env_file:
      - .env
      - .train
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [ gpu ]
    volumes:
      - .cache/huggingface/:/root/.cache/huggingface/
      - .cache/unsloth_compiled_cache/:/trainer/unsloth_compiled_cache/

  train:
    build:
      context: .
      dockerfile: dockers/train.Dockerfile
    env_file:
      - .env
      - .train
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [ gpu ]
    volumes:
      - .cache/huggingface/:/root/.cache/huggingface/
      - .cache/unsloth_compiled_cache/:/trainer/unsloth_compiled_cache/

  distill:
    build:
      context: .
      dockerfile: dockers/distill.Dockerfile
    env_file:
      - .env
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      - VLLM_WORKER_MULTIPROC_METHOD=spawn
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [ gpu ]
    ports:
      - "8265:8265"
    command: >
      uv run main.py distill
      --limit 100
      --publish
      --dataset-repo-id gretelai/synthetic_text_to_sql
      --publish-repo-id ${NAMESPACE}/sql-distill-Llama-3.2-1B-reasoning
      --provider HuggingFace
      --model meta-llama/Llama-3.2-1B
      --validate
      --private-repo
      --batch-size 64

  jupyter:
    build:
      context: .
      dockerfile: dockers/jupyter.Dockerfile
    env_file:
      - .env
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
    ports:
      - "8888:8888"
      - "8000:8000"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [ gpu ]
    volumes:
      - ./notebooks:/jupyter/notebooks